---
title: "Market_Basket_Analysis"
author: "Ashiqur"
date: "11/2/2019"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(echo = TRUE)
```
## Load library
```{r Library, message=FALSE}
library(RMySQL)
library(dplyr)
library(ggplot2)
library(arules)
library(arulesViz)
```

## Load Data
There are three table in the SQL database server.below code is the procedure to retrieve the 
table from the server
#### Connecting to db
```{r Connecting_to_db}
db_user <- 'data_student_berlin'
db_password <- 'waai_has_shitty_internet'
db_name <- 'pricehub'
db_table <- 'products'
db_host <- '34.89.228.59' # for local access
db_port <- 3306

mydb <-  dbConnect(MySQL(), user = db_user, password = db_password,
                   dbname = db_name, host = db_host, port = db_port)
```
#### Read data from db
```{r read_data,warning=FALSE}
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
products <-  fetch(rs, n = -1)
```

### Import df 'line_item'
```{r line_table,warning=FALSE}
db_table <- 'line_item'
s <- paste0("select * from ", db_table)
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
line_item <-  fetch(rs, n = -1)
```


### Import df 'orders'
```{r orders_table,warning=FALSE}
db_table <- 'orders'
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
orders <-  fetch(rs, n = -1)
```

### import df 'products'
```{r products_table,warning=FALSE}
db_table <- 'products'
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
products <-  fetch(rs, n = -1)
```
### Disconnect from database 
```{r exit,warning=FALSE}
on.exit(dbDisconnect(mydb))
```

## Check for missing values
check and count how many missing value is in the table
```{r missing_value}
any(is.na(line_item))
any(is.na(orders))
any(is.na(products))


sum(is.null(line_item))
sum(is.null(products))
sum(is.null(orders))
```

## Exploring three dataset

```{r Summarise data}
glimpse(c(line_item, orders, products))

summary(c(line_item, orders, products))

str(c(line_item, orders, products))

sum(is.na(c(line_item, orders, products)))
```

## Price difference in line_item and order:
Explore the relationship between prices in line_item and order:

```{r manual_price_calculate}
head(line_item)
dim(line_item)
line_price <- line_item %>% 
        group_by(id_order) %>% 
        summarise(count_price = sum(product_quantity * unit_price))
      
dim(line_price)
head(line_price,50)
#line_new<-inner_join(line_item,line_price,by="id_order")
#head(line_new)
#dim(line_new)
```
counting id_order which is present only in both the table and calculate the price error
```{r price_compare}

compare_total<-inner_join(line_price,orders,by="id_order")
head(compare_total)
dim(compare_total)

#mutate(compare_total,price_diff=total_paid-count_price)
compare_total$price_diff<-compare_total$count_price-compare_total$total_paid
compare_total$perc_diff <- round(((compare_total$count_price - compare_total$total_paid)/compare_total$total_paid)*100)
head(compare_total)
dim(compare_total)

```
### Plot histogram 
To check the frequency of price difference 
```{r hist_price_diff}
compare_total %>% 
        filter(price_diff < 20, price_diff > -20) %>% 
        ggplot(aes(price_diff)) +
        geom_histogram()
```

### Correct Value
```{r correct_price diff}
correct_price<-filter(compare_total,price_diff==0) 
head(correct_price)
dim(correct_price)
```

### In-correct Value
There is some unexpected price difference that has noticed.so only price difference (-10 to 10 )value has been considered
```{r incorrect_price diff}
incorrect_price<-filter(compare_total,price_diff!=0) 
head(incorrect_price)
dim(incorrect_price)
summary(incorrect_price)
```

### Select value
price difference from  -10 to +10 has considered
```{r select}
comp_10_f<-filter(compare_total,price_diff>=(-10) & price_diff<10)
count(comp_10_f)
head(comp_10_f)
dim(comp_10_f)

# if we take percentage valu
#comp_10_f <- filter(comp_10_f, perc_diff < 10)
#comp_10_f <- filter(comp_10_f, perc_diff > -10)
```
### Plot Total paid vs price difference  
```{r price_diff_plot}
#ggplot(mapping = aes(y=comp_10_f$total_paid,x=comp_10_f$price_diff))+geom_point()
comp_10_f  %>%
  ggplot(aes(x=total_paid, y=price_diff)) + 
  geom_point()
```

### Suspicious value

values have not been considered 
```{r suspicious}
suspicious_df<-anti_join(line_item,comp_10_f,by="id_order")
summary(suspicious_df)
dim(suspicious_df)

```

## Price difference in line_item and products:
counting sku which is present only in both the table and calculate the price error
```{r sku}
head(products)
comp_sku<-inner_join(line_item, products, by="sku")
dim(comp_sku)
head(comp_sku)
summary(comp_sku)

comp_sku$sku_p_diff=comp_sku$price- comp_sku$unit_price 
head(comp_sku)
```
# Plot price difference vs price 
To check the frequency of price difference 
```{r sku_plot}
#ggplot(mapping = aes(y=comp_sku$price,x=comp_sku$sku_p_diff))+geom_jitter()

comp_sku  %>%
  ggplot(aes(x=sku_p_diff, y=price)) + 
  geom_point()
```
### Plot histogram 
To check the frequency of price difference 
```{r hist_price_dif}
comp_sku %>% 
        filter(sku_p_diff < 1000, sku_p_diff > -1000) %>% 
        ggplot(aes(sku_p_diff)) +
        geom_histogram()
```

### Select value
price difference from  -10 to +10 has considered
```{r select_p}
sku_1000_f<-filter(comp_sku,sku_p_diff>=(-1000) & sku_p_diff<1000)
count(sku_1000_f)
head(sku_1000_f)
```
### Correct sku value
```{r correct_sku }
correct_sku_price<-filter(comp_sku,sku_p_diff==0) 
head(correct_sku_price)
dim(correct_sku_price)
```
### In-Correct sku value
```{r incorrect_sku }
suspicious_sku<-anti_join(line_item,sku_1000_f,by="sku")
summary(suspicious_sku)
dim(suspicious_sku)
```
### Crosscheck 
Check similer ID_order we deleted from both cases
```{r crosscheck}
head(suspicious_sku)
dim(suspicious_sku)
head(suspicious_df)
dim(suspicious_df)

comp_suspicious<-inner_join(suspicious_df, suspicious_sku, by="id_order")
head(comp_suspicious)
dim(comp_suspicious)
```
### Select Some specific value
only  Completed item has been chosen  from line_item table
```{r select_completed}
comp_10_f_add3 <- filter(comp_10_f, (state == "Completed" |state == "Pending"|state == "Place order"))
comp_10_f_comp<-filter(comp_10_f,state == "Completed" )
dim(comp_10_f_comp)
head(comp_10_f_comp)
```
### Final table
After checking the prices and excluding the ones that are not explainable, 
we now have to join two exploratory data sets with the final dataset. 
```{r final_table}


#line_new<-inner_join(line_item,line_price,by="id_order")
#head(line_new)

dim(comp_10_f_comp)
head(comp_10_f_comp)
dim(comp_sku)
head(comp_sku)


dim(sku_1000_f)
nrow(unique(sku_1000_f))
nrow(duplicated(sku_1000_f))
head(sku_1000_f)
final_table<-comp_10_f_comp %>% 
             filter(id_order %in% sku_1000_f$id_order)
final_table_add3<-comp_10_f_add3 %>% 
             filter(id_order %in% sku_1000_f$id_order)

dim(final_table)
head(final_table)
nrow(unique(final_table))

final_final <- inner_join(final_table, line_item, by="id_order")
final_final_add3 <- inner_join(final_table_add3, line_item, by="id_order")
head(final_final,50)
dim(final_final)
nrow(unique(final_final))
view(final_final)
dim(final_final_add3)

#(duplicated(final_final$id_order))

```
## Explore data set

Check that all orders in line_item are present in our orders dataset. 
Exclude from line_item any rows that do not meet that condition.
```{r Explore1 }
#using inner_join
new_Line_item<-inner_join(line_item,orders,by="id_order")
dim(new_Line_item)
head(new_Line_item)
dim(line_item) - dim(new_Line_item)
#list of the value of id_order which is present in order dataset
list_common<-line_item[line_item$id_order %in% new_Line_item$id_order,]
count(list_common)

#list of the value of id_order which is not present  in order table
list_notcommon<-line_item[!(line_item$id_order %in% new_Line_item$id_order),]
count(list_notcommon)

```
Exclude from line_item any rows from orders that are not “Completed”.After filtering for completed orders we are left with 62103 observations. 
 We removed almost 79% of observations that were not completed
```{r Explore2 }
new_Line_item_com <- filter(new_Line_item, state == "Completed")
dim(new_Line_item_com)
head(new_Line_item_com)
(dim(line_item) - dim(new_Line_item_com))/dim(line_item)*100
```
Check that all products in line_item are present in the products dataset. 
Exclude from line_item any rows that do not meet that condition.
```{r Explore3}
new_Line_item2 <- inner_join(new_Line_item_com, products, by="sku")
dim(new_Line_item2)
head(new_Line_item2)
dim(new_Line_item_com) - dim(new_Line_item2)


#list of the value of sku which is present in order dataset
list_sku<-line_item[line_item$sku %in% new_Line_item2$sku,]
count(list_sku)
#list of the value of sku which is not present  in order table
count(line_item[!(line_item$sku %in% new_Line_item2$sku),])
```
After inner join of line_item_new and products table we have check if all products from line_item are present in the products table. Our final dataset has 61700 observation

## Cleaning and preprocessing
Let's transform and format the created_date column, make two new colomns Date and Time 
and remove the created_date and date columns
```{r Explore4}
new_Line_item2$Date <- as.Date(new_Line_item2$created_date)
new_Line_item2$Time <- format(as.POSIXct(new_Line_item2$created_date), format="%H:%M:%S")

new_Line_item2$date <- NULL
new_Line_item2$created_date <- NULL

dim(new_Line_item2)
head(new_Line_item2)
```

## Market Basket Analysis
We will use Association Rules by applying "Apriori Algorithm" to do this analysis.

#### Write data
```{r write_data }
head(final_final)
dim(final_final)

final_df<-select(final_final_add3,id_order,sku)
head(final_df)
dim(final_df)
df_without_1<-final_df %>% 
  group_by(id_order) %>% 
  count(id_order)
head(df_without_1)
dim(df_without_1)
#excluding transactions of size 1

df_without_1<-df_without_1 %>% 
  filter(n!=1)
head(df_without_1)
dim(df_without_1)

df_tr_1<-final_df[final_df$id_order %in% df_without_1$id_order, ]
head(df_tr_1)
dim(df_tr_1)


write.csv(df_tr_1, "final_df.csv", row.names = FALSE)
```

#### Create a transactional file
```{r transaction }
transactional_df<- read.transactions(("final_df.csv"), format = "single", 
  header = TRUE, sep = ",", cols = c("id_order","sku"))

inspect(transactional_df)



```

#### Get to know my transactional data
```{r Explore_data}
#To view the transaction
inspect(transactional_df)
#To view certain number of transactions
inspect(transactional_df[1:16])
# Number of transactions.
length(transactional_df)
# Number of items per transaction 
size(transactional_df[6:16]) 
# Lists the transactions by conversion 
LIST(transactional_df[6:16]) 
# To see the item labels 
itemLabels(transactional_df) 

#visualise the items within your dataset

#Least frequent product
least<-itemFrequency(transactional_df)
plot_bar<-barplot(sort(least, decreasing=T))
#frequentItems <- eclat(transactional_df,parameter = list(supp = 0.007, maxlen = 30))

#Most frequent product
itemFrequency(transactional_df)["APP1184"]
itemFrequency(transactional_df)[c("APP1184","APP1916","APP1916")]



itemFrequencyPlot(transactional_df,topN=20,type="absolute",col = rainbow(20),cex.name=0.7)
#Is there a way to plot using certain metrics?
head(transactional_df)

summary(transactional_df)

#visualise the transactions within your dataset

image(transactional_df,xcol=20,ycol=20,asp=3)

image(sample(transactional_df,2000))

```
After obserbing the summary, i have found most frequent items is APP1184 and it sold 925 times
and the average is 1.32.single item are sold 34872 times.

## Apply the apriori algorithm
```{r apriori_al}
trans_rules<-apriori(transactional_df,parameter = list(supp = 0.001, conf = 0.7))#2
trans_rules<-apriori(transactional_df,parameter = list(supp = 0.001, conf = 0.1))#1
trans_rules<-apriori(transactional_df,parameter = list(supp = 0.001, conf = 0.007))#7
trans_rules<-apriori(transactional_df,parameter = list(supp = 0.0004, conf = 0.007, minlen = 2))#232

trans_rules<-apriori(transactional_df,parameter = list(supp = 100/length(trans_rules), conf = 0.007, minlen = 2))#232

#trans_rules<-trans_rules[!redundant_rules]
#inspact(trans_rules[20])

#subset(trans_rules,rhs %in% c("APP1184 "))
#inspect(subset(trans_rules,rhs %in% c("APP1184 ")))

#when both at the same time(add a inside %)
#inspect(subset(trans_rules,lhs %ain% c("APP1184 ","APP1916")))

#when at least one at the same time
#inspect(subset(trans_rules,lhs %in% c("APP1184 ","APP1916")))

summary(trans_rules)
inspect(trans_rules)
trans_rules<-sort(trans_rules, by="confidence", decreasing=TRUE)
inspect(trans_rules)
#inspect(trans_rules[1:20])
#redundant_tr_rules<-is.redundant(trans_rules)
#summary(redundant_tr_rules)
```